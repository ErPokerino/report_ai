{
  "hash": "7809d8e5fd455b16db2f634774b4cc73",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Report Analisi Lucy - Sistema Riconoscimento Documentale\"\nauthor: \"Sistema Automatico\"\ndate: today\nparams:\n  dataset_path: \"../data/lucy_data.csv\"\n  enable_ai: true\nformat:\n  html:\n    code-fold: true\n    toc: true\n    number-sections: true\n    css: ../styles.css\n  pdf:\n    toc: true\n    geometry:\n      - top=30mm\n      - left=20mm\n      - right=20mm\n      - bottom=30mm\n      - heightrounded\n    fig-dpi: 300\n    keep-tex: false\n    colorlinks: true\n    linestretch: 1.2\n    fontsize: 11pt\n    fig-pos: \"H\"\n    include-in-header:\n      text: |\n        \\usepackage{wrapfig}\n        \\usepackage{float}\n        \\sloppy\n        \\emergencystretch=3em\n  revealjs:\n    theme: dark\n    transition: slide\n    code-fold: true\n    toc: true\n---\n\n## Introduzione\n\nQuesto report analizza i dati del sistema Lucy, applicativo documentale per la gestione delle fatture di Luxottica. Il sistema utilizza algoritmi di riconoscimento automatico (incluso ML con XGBoost) per estrarre informazioni dalle fatture, estraendo **tutti i campi** indicati in `field_name`.\n\nLe analisi e i commenti sono generati automaticamente utilizzando **LangChain** e modelli LLM (GPT-5.2) per fornire insights strutturati sui dati.\n\n## Caricamento Dati\n\n::: {#d378bc21 .cell execution_count=1}\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Statistiche Dati**\n\n| Metrica           | Valore                                                |\n|:------------------|:------------------------------------------------------|\n| Righe             | 82,756                                                |\n| Colonne           | 16                                                    |\n| Periodo           | 2025-12-06 19:23:57+00:00 - 2025-12-12 22:51:59+00:00 |\n| Record validati   | 19,286 (23.3%)                                        |\n| Metodi utilizzati | 12                                                    |\n| Protocolli unici  | 41,378                                                |\n| Fornitori unici   | 213                                                   |\n:::\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Distribuzione e Statistiche per Campo (field_name)**\n\n| field_name    |   Totale record |   Validati | % Validati   |   Metodi utilizzati |\n|:--------------|----------------:|-----------:|:-------------|--------------------:|\n| autovalidated |           41378 |       9643 | 23.3%        |                   3 |\n| id_subject    |           41378 |       9643 | 23.3%        |                   9 |\n:::\n\n::: {.cell-output .cell-output-display}\n![](report_lucy_files/figure-html/cell-2-output-3.png){width=947 height=566}\n:::\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Prime righe del dataset**\n\n|   protocol |   id_company | country   | field_name    | pred   |   truth |   comparison | method_pred   |   confidence | datetime_sent             | date       |   hour | day_of_week   | is_validated   | is_correct   | method_type   |\n|-----------:|-------------:|:----------|:--------------|:-------|--------:|-------------:|:--------------|-------------:|:--------------------------|:-----------|-------:|:--------------|:---------------|:-------------|:--------------|\n|   29150044 |          254 | DE        | autovalidated | True   |     nan |          nan | xgboost       |        0.637 | 2025-12-10 07:22:04+00:00 | 2025-12-10 |      7 | Wednesday     | False          |              | Other         |\n|   29192338 |          254 | DE        | autovalidated | False  |     nan |          nan | xgboost       |        0.433 | 2025-12-11 21:37:33+00:00 | 2025-12-11 |     21 | Thursday      | False          |              | Other         |\n|   29077751 |          254 | DE        | autovalidated | False  |     nan |          nan | xgboost       |        0.989 | 2025-12-08 12:24:07+00:00 | 2025-12-08 |     12 | Monday        | False          |              | Other         |\n|   29199027 |          254 | DE        | autovalidated | True   |     nan |          nan | xgboost       |        0.842 | 2025-12-12 09:52:47+00:00 | 2025-12-12 |      9 | Friday        | False          |              | Other         |\n|   29176455 |          254 | DE        | autovalidated | True   |     nan |          nan | xgboost       |        0.797 | 2025-12-11 09:23:10+00:00 | 2025-12-11 |      9 | Thursday      | False          |              | Other         |\n:::\n\n::: {.cell-output .cell-output-display}\n![](report_lucy_files/figure-html/cell-2-output-5.png){width=947 height=566}\n:::\n:::\n\n\n### Distribuzione Campi (field_name)\n\n::: {#cell-fig-field-distribution .cell fig-height='6' fig-width='10' execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![Distribuzione dei campi (field_name) nel dataset](report_lucy_files/figure-html/fig-field-distribution-output-1.png){#fig-field-distribution width=947 height=566 fig-pos='H'}\n:::\n:::\n\n\n### Riassunto Analitico Generale\n\n\n\n## 1) Volume e copertura dei dati\n\n- **Record totali:** **82.756**\n- **Campi estratti (field_name):**\n  - **autovalidated:** 41.378 (50,0%)\n  - **id_subject:** 41.378 (50,0%)\n- **Record con validazione umana:** **19.286 / 82.756 = 23,3%**\n  - Implicazione: circa **3 record su 4** restano senza verifica, quindi molte metriche “operative” (es. accuratezza reale) non sono direttamente stimabili sull’intero dataset senza assunzioni.\n\nDati numerici utili:\n- **Confidence** (82.597 non null): media **0,815**, mediana **0,933**, IQR **0,66–0,995** → distribuzione tendenzialmente alta, ma con coda verso valori bassi (min 0).\n- **Fascia oraria (hour):** media **14,63**, mediana **15** → invii/estrazioni concentrati nel pomeriggio.\n\n---\n\n## 2) Performance generale dei metodi di riconoscimento (proxy: mix di utilizzo)\n\nNon sono forniti tassi di *is_correct* per metodo, quindi la “performance” osservabile qui è soprattutto **copertura/adozione** dei metodi (quanto contribuiscono al totale), non l’accuratezza.\n\nDistribuzione *method_pred* (quota su 82.756):\n- *xgboost*: **36.336** (**43,9%**) → principale motore di predizione\n- *azure_model*: **18.739** (**22,6%**) → secondo canale per volume\n- *logo*: **11.436** (**13,8%**) → componente rilevante (probabile identificazione fornitore/brand)\n- *query-vat_number*: **5.240** (**6,3%**) → lookup deterministico su P.IVA\n- *no_method*: **5.022** (**6,1%**) → casi senza metodo applicato (area critica)\n- *similarity*: **2.575** (**3,1%**) → matching fuzzy (casi ambigui o testo rumoroso)\n- Metodi “long tail” (complessivi **~2,0%**): *query-supplier_name*, *query-name_like*, *query-phone*, *query-fiscal_code*, *query-supplier_code*\n- *fallback*: **20** (**0,02%**) → usato raramente (ma importante da monitorare perché spesso indice di casi limite)\n\nLettura operativa:\n- Il sistema è dominato da un approccio **ML + modello esterno** (*xgboost* + *azure_model* = **66,5%** dei record).\n- I metodi di tipo *query-* coprono circa **~7–9%** (a seconda se si includono tutte le varianti), suggerendo un livello discreto di recupero “regolistico/deterministico”.\n- La presenza non trascurabile di *no_method* (6,1%) indica **buchi di orchestrazione**, input non riconosciuto o regole di routing incomplete.\n\n---\n\n## 3) Osservazioni sul sistema di validazione\n\n- **Copertura di validazione limitata (23,3%)**: la qualità reale del sistema può essere stimata con affidabilità **solo** su questo sottoinsieme. Se il campionamento dei validati non è casuale (tipicamente si validano i casi “difficili”), le metriche sul validato possono essere **pessimistiche** rispetto al totale.\n- La presenza di un campo *autovalidated* (metà dei record) suggerisce un meccanismo di *auto-validazione* (es. soglia su *confidence*, regole, o consenso tra metodi/*ensemble*). Senza dettaglio su *is_validated* vs *autovalidated*, è utile verificare:\n  - quanta parte di *autovalidated* è anche validata umanamente,\n  - eventuali errori sistematici “accettati” automaticamente (rischio di *false positive* ad alta *confidence*).\n- **Segnali di rischio da monitorare** (priorità pratica):\n  - casi *no_method* e *fallback*: spesso correlati a formati nuovi, OCR degradato o regole mancanti;\n  - differenze di *confidence* tra metodi (qui non segmentate): utile confrontare, sul sottoinsieme validato, accuratezza vs *confidence* per calibrare soglie di *auto-validazione*.\n\n--- \n\n### Sintesi\n- Dataset ampio (**82.756** record) ma con **validazione umana su ~1/4** dei casi.\n- Predizione fortemente trainata da *xgboost* e *azure_model*; metodi deterministici *query-* coprono una quota minoritaria ma strategica.\n- L’area più “critica” dal punto di vista di controllo qualità è la combinazione di *autovalidated* + bassa copertura di validazione, insieme al **6,1%** di *no_method* (potenziale perdita di copertura o casi non gestiti).\n\n\n## Overview Dati\n\n### Distribuzione Metodi\n\n::: {#cell-fig-method-usage .cell fig-height='6' fig-width='10' execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![Distribuzione dell'uso dei metodi di riconoscimento](report_lucy_files/figure-html/fig-method-usage-output-1.png){#fig-method-usage width=950 height=566 fig-pos='H'}\n:::\n:::\n\n\n::: {#b3f4a2e8 .cell execution_count=6}\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Commento AI:** La distribuzione mostra una forte concentrazione su pochi metodi: *xgboost* è nettamente dominante (36.336 casi), seguito da *azure_model* (18.739) e *logo* (11.436). Questo pattern suggerisce un *routing* principale che privilegia un classificatore/estrattore centrale (*xgboost*) con un secondo canale rilevante (*azure_model*) e un supporto basato su segnali visivi (*logo*). Nel complesso, i primi tre metodi coprono la maggior parte dei casi, indicando una pipeline orientata a massimizzare copertura e automazione tramite componenti “core”.\n\nAl di sotto del blocco principale, emerge una “coda lunga” di metodi *query-* (es. *query-vat_number*, *query-supplier_name*, *query-phone*), tipicamente legati a strategie di recupero/normalizzazione puntuale. La presenza non trascurabile di *no_method* (5.022) segnala però una quota di documenti per cui il sistema non attiva alcuna strategia, elemento potenzialmente critico in ottica di completamento e robustezza.\n\n---\n\n## Punti di interesse/anomalie\n\n- **Dominanza di *xgboost***: il metodo principale vale ~2× *azure_model* e ~3× *logo*, suggerendo un forte accentramento del traffico su un singolo componente (possibile rischio di “single point of failure” o bias di instradamento).\n- **Quota significativa di *no_method* (5.022)**: numero comparabile a *query-vat_number* (5.240). Potrebbe indicare:\n  - regole di *routing* che non matchano alcuni casi,\n  - errori/assenze nei campi necessari per attivare le *query*,\n  - problemi di logging o di tracciamento della scelta del metodo.\n- **Uso ridotto di *similarity* (2.575)**: se progettato come metodo di recupero robusto (fuzzy match), potrebbe essere sotto-utilizzato rispetto alla potenziale utilità nei casi “sporchi” o incompleti.\n- **Metodi di emergenza quasi assenti**: *fallback* (20) è estremamente basso; se il *fallback* dovrebbe intercettare gli insuccessi, questo valore può suggerire:\n  - *fallback* non correttamente configurato/attivato,\n  - fallimenti che confluiscono in *no_method* invece che in *fallback*,\n  - soglie troppo restrittive o ramo di codice raramente raggiunto.\n- **Coda lunga frammentata dei metodi *query-***: molti metodi con volumi simili (es. *query-name_like* 890, *query-phone* 887) indicano micro-strategie che potrebbero essere accorpate o meglio orchestrate in un’ottica di *ensemble*.\n\n---\n\n## Raccomandazioni operative\n\n- **Analizzare e ridurre *no_method***:\n  - introdurre un *fallback* “sempre attivo” (o un *routing* di default) quando nessun metodo viene selezionato,\n  - creare una tassonomia delle cause (es. campi mancanti, errori OCR, timeouts, regole non soddisfatte) con metriche dedicate.\n- **Verificare la coerenza tra *fallback* e *no_method***:\n  - audit della logica di instradamento e dei log (eventi di selezione metodo),\n  - definire chiaramente quando un caso deve finire in *fallback* vs *no_method*.\n- **Ottimizzare il *routing* tra *xgboost* e *azure_model***:\n  - eseguire un *A/B test* o test controllati su segmenti (per lingua, layout, qualità scansione) per capire dove *azure_model* supera *xgboost* e viceversa,\n  - introdurre soglie di confidenza per deviare a *azure_model* o a metodi alternativi quando *xgboost* è incerto.\n- **Rivalutare il ruolo di *similarity***:\n  - aumentare l’attivazione di *similarity* come rete di sicurezza per casi con anagrafiche rumorose,\n  - misurare impatto su precision/recall e tempi, eventualmente con *routing* condizionale (es. bassa confidenza su campi chiave).\n- **Razionalizzare i metodi *query-***:\n  - consolidare *query-name_like*, *query-supplier_name*, *query-phone* in un modulo unico di *entity resolution* con priorità e scoring,\n  - monitorare performance per metodo (success rate, override rate, downstream correction rate) per eliminare rami a basso rendimento.\n- **Cruscotto di controllo consigliato** (minimo):\n  - distribuzione metodi nel tempo, tasso di *no_method*, tasso di attivazione *fallback*, e qualità per metodo (accuratezza/correzioni manuali) per individuare drift e regressioni.\n:::\n:::\n\n\n### Timeline Predizioni\n\n::: {#cell-fig-timeline .cell fig-height='6' fig-width='12' execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![Timeline delle predizioni nel tempo per metodo](report_lucy_files/figure-html/fig-timeline-output-1.png){#fig-timeline width=1333 height=566 fig-pos='H'}\n:::\n:::\n\n\n::: {#5e48634e .cell execution_count=8}\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Commento AI:** Nel periodo **2025-12-06 19:23:57 UTC → 2025-12-12 22:51:59 UTC**, la timeline delle predizioni evidenzia un comportamento complessivamente “a finestre”: l’attività non risulta perfettamente uniforme nel tempo, ma tende a concentrarsi in specifici intervalli, suggerendo batch operativi, picchi di traffico o una logica di *routing* che privilegia alcuni percorsi in determinate fasce.\n\nCon **12 metodi** in parallelo, il pattern più rilevante da osservare (e tipicamente visibile in questo tipo di grafico) è la **coerenza o alternanza** tra metodi: se le predizioni si distribuiscono stabilmente tra più metodi, è indicativa di un *ensemble* o di una strategia multi-modello; se invece si notano fasi in cui un metodo domina e poi “cede” ad altri, questo è spesso compatibile con *fallback* attivati (per qualità, timeout, errori di parsing o regole di confidenza).\n\n---\n\n## Punti di interesse/anomalie\n\n- **Discontinuità temporali** (periodi senza predizioni o con drastica riduzione): possono indicare\n  - stop di pipeline / job scheduler,\n  - degrado di integrazione con sistemi a monte,\n  - backpressure o code non smaltite.\n- **Dominanza improvvisa di un singolo metodo** rispetto agli altri:\n  - possibile cambio di regole di *routing*,\n  - attivazione di *fallback* sistematico verso un metodo “di sicurezza”,\n  - regressione di performance o instabilità negli altri metodi.\n- **Alternanza rapida tra metodi** nello stesso intervallo (switching frequente):\n  - segnala logiche di *fallback* basate su soglie troppo sensibili,\n  - oppure un *A/B test* non correttamente “sticky” (assenza di assegnazione stabile per documento/tenant).\n- **Concorrenza e sovrapposizione** (molti metodi che producono predizioni nello stesso timestamp o finestra molto stretta):\n  - possibile esecuzione ridondante (costi/latency),\n  - oppure strategia *ensemble* non ottimizzata (mancanza di gating per evitare chiamate inutili).\n\n---\n\n## Raccomandazioni operative\n\n- Verificare e documentare le regole di *routing*:\n  - assicurarsi che la selezione del metodo sia **deterministica** per classi di fattura/fornitore/lingua,\n  - introdurre “stickiness” se è attivo un *A/B test* (assegnazione stabile per evitare rumore nella timeline).\n- Strumentare in modo esplicito i motivi di *fallback*:\n  - loggare causa (timeout, bassa confidenza, errore OCR, eccezione di parsing) per correlare i picchi di switching.\n- Definire KPI per metodo e monitorarli lungo la timeline:\n  - **tasso di utilizzo**, **latenza**, **errore/exception rate**, **confidence media**, e **coverage** (quante fatture ciascun metodo riesce a processare).\n- Se emerge dominanza di un metodo “di sicurezza”, pianificare un’analisi di regressione:\n  - confrontare release/configurazioni nel periodo,\n  - verificare dipendenze esterne (quote, rate limit, credenziali, endpoint).\n- Ottimizzare eventuale *ensemble* con gating:\n  - eseguire metodi costosi solo quando necessario (es. in base a segnali OCR/qualità immagine),\n  - ridurre invocazioni parallele ridondanti per contenere costi e variabilità di latenza.\n\nSe mi condividi i nomi dei 12 metodi (es. *azure_model*, *query-vat_number*, ecc.) e ciò che rappresenta “predizione” nel grafico (conteggio, esito, confidenza, classe), posso rendere il commento più specifico, citando quali *metodi* mostrano picchi, alternanze o anomalie puntuali.\n:::\n:::\n\n\n## Analisi per Campo\n\n::: {#90245245 .cell execution_count=9}\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n### Analisi: autovalidated\n:::\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Statistiche per autovalidated**\n\n| Metrica           | Valore        |\n|:------------------|:--------------|\n| Totale record     | 41,378        |\n| Record validati   | 9,643 (23.3%) |\n| Metodi utilizzati | 3             |\n:::\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Metriche di Performance per autovalidated**\n\n| method    | method_type   |   precision |   recall |    f1 |   accuracy |   total |\n|:----------|:--------------|------------:|---------:|------:|-----------:|--------:|\n| xgboost   | Other         |       0.962 |    0.774 | 0.858 |      0.782 |    7936 |\n| no_method | Other         |       0     |    0     | 0     |      1     |    1705 |\n| fallback  | Other         |       0     |    0     | 0     |      1     |       2 |\n:::\n\n::: {.cell-output .cell-output-display}\n![](report_lucy_files/figure-html/cell-10-output-4.png){width=1142 height=565}\n:::\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n---\n:::\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n### Analisi: id_subject\n:::\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Statistiche per id_subject**\n\n| Metrica           | Valore        |\n|:------------------|:--------------|\n| Totale record     | 41,378        |\n| Record validati   | 9,643 (23.3%) |\n| Metodi utilizzati | 9             |\n:::\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Metriche di Performance per id_subject**\n\n| method              | method_type   |   precision |   recall |    f1 |   accuracy |   total |\n|:--------------------|:--------------|------------:|---------:|------:|-----------:|--------:|\n| azure_model         | ML            |       0.946 |        1 | 0.972 |      0.946 |    4710 |\n| query-vat_number    | Query         |       0.974 |        1 | 0.987 |      0.974 |    1334 |\n| logo                | Other         |       0.999 |        1 | 0.999 |      0.999 |    1799 |\n| similarity          | Other         |       0.896 |        1 | 0.945 |      0.896 |     801 |\n| query-supplier_code | Query         |       0.988 |        1 | 0.994 |      0.988 |      80 |\n| query-name_like     | Query         |       0.854 |        1 | 0.921 |      0.854 |     295 |\n| query-supplier_name | Query         |       0.94  |        1 | 0.969 |      0.94  |     266 |\n| query-phone         | Query         |       0.957 |        1 | 0.978 |      0.957 |     304 |\n| query-fiscal_code   | Query         |       0.964 |        1 | 0.982 |      0.964 |      28 |\n:::\n\n::: {.cell-output .cell-output-display}\n![](report_lucy_files/figure-html/cell-10-output-9.png){width=1142 height=565}\n:::\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n---\n:::\n\n::: {.cell-output .cell-output-display}\n![](report_lucy_files/figure-html/cell-10-output-11.png){width=1142 height=565}\n:::\n\n::: {.cell-output .cell-output-display}\n![](report_lucy_files/figure-html/cell-10-output-12.png){width=1142 height=565}\n:::\n:::\n\n\n## Performance Metodi\n\n### Calcolo Metriche (Aggregate)\n\n::: {#218dc04e .cell execution_count=10}\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Metriche di Performance per Metodo (Aggregate - Tutti i Campi)**\n\n| method              | method_type   |   precision |   recall |    f1 |   accuracy |   total |\n|:--------------------|:--------------|------------:|---------:|------:|-----------:|--------:|\n| xgboost             | Other         |       0.962 |    0.774 | 0.858 |      0.782 |    7936 |\n| no_method           | Other         |       0     |    0     | 0     |      1     |    1705 |\n| azure_model         | ML            |       0.946 |    1     | 0.972 |      0.946 |    4710 |\n| query-vat_number    | Query         |       0.974 |    1     | 0.987 |      0.974 |    1334 |\n| logo                | Other         |       0.999 |    1     | 0.999 |      0.999 |    1799 |\n| similarity          | Other         |       0.896 |    1     | 0.945 |      0.896 |     801 |\n| query-supplier_code | Query         |       0.988 |    1     | 0.994 |      0.988 |      80 |\n| query-name_like     | Query         |       0.854 |    1     | 0.921 |      0.854 |     295 |\n| query-supplier_name | Query         |       0.94  |    1     | 0.969 |      0.94  |     266 |\n| query-phone         | Query         |       0.957 |    1     | 0.978 |      0.957 |     304 |\n| query-fiscal_code   | Query         |       0.964 |    1     | 0.982 |      0.964 |      28 |\n| fallback            | Other         |       0     |    0     | 0     |      1     |       2 |\n:::\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Metriche di Performance per Campo e Metodo**\n\n| field_name    | method              |   precision |   recall |    f1 |   accuracy |   total |\n|:--------------|:--------------------|------------:|---------:|------:|-----------:|--------:|\n| autovalidated | xgboost             |       0.962 |    0.774 | 0.858 |      0.782 |    7936 |\n| autovalidated | no_method           |       0     |    0     | 0     |      1     |    1705 |\n| autovalidated | fallback            |       0     |    0     | 0     |      1     |       2 |\n| id_subject    | azure_model         |       0.946 |    1     | 0.972 |      0.946 |    4710 |\n| id_subject    | query-vat_number    |       0.974 |    1     | 0.987 |      0.974 |    1334 |\n| id_subject    | logo                |       0.999 |    1     | 0.999 |      0.999 |    1799 |\n| id_subject    | similarity          |       0.896 |    1     | 0.945 |      0.896 |     801 |\n| id_subject    | query-supplier_code |       0.988 |    1     | 0.994 |      0.988 |      80 |\n| id_subject    | query-name_like     |       0.854 |    1     | 0.921 |      0.854 |     295 |\n| id_subject    | query-supplier_name |       0.94  |    1     | 0.969 |      0.94  |     266 |\n| id_subject    | query-phone         |       0.957 |    1     | 0.978 |      0.957 |     304 |\n| id_subject    | query-fiscal_code   |       0.964 |    1     | 0.982 |      0.964 |      28 |\n:::\n:::\n\n\n### Grafico Metriche\n\n::: {#cell-fig-metrics .cell fig-height='6' fig-width='12' execution_count=11}\n\n::: {.cell-output .cell-output-display}\n![Metriche di performance (Precision, Recall, F1, Accuracy) per metodo](report_lucy_files/figure-html/fig-metrics-output-1.png){#fig-metrics width=1142 height=565 fig-pos='H'}\n:::\n:::\n\n\n::: {#8131985a .cell execution_count=12}\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Commento AI:** Dal grafico emerge una netta separazione tra metodi “forti” basati su interrogazioni puntuali (*query-…*) e segnali strutturati (*logo*, *azure_model*) rispetto a metodi più “generici” (*xgboost*) o non applicativi (*no_method*, *fallback*). La maggior parte delle strategie *query* mostra **recall = 1.0**, indicando un’ottima capacità di intercettare i casi positivi quando la chiave di ricerca è disponibile e correttamente estratta.\n\nSul fronte della precision, i metodi più affidabili risultano *logo* (precision ≈ 0.999) e *query-supplier_code* (≈ 0.988), seguiti da *query-vat_number* (≈ 0.974) e *query-fiscal_code* (≈ 0.964). Al contrario, *xgboost* evidenzia un **trade-off** marcato: precision elevata (≈ 0.962) ma recall più basso (≈ 0.774), con conseguente F1 più contenuto (≈ 0.858) e accuracy inferiore (≈ 0.782) rispetto ai migliori metodi.\n\n---\n\n## Punti di interesse/anomalie\n\n- *no_method* e *fallback* hanno **accuracy = 1.0** ma precision/recall/F1 = 0.0: pattern tipico di classi “nessuna predizione” o casi in cui il metodo **non produce match**. Questo suggerisce un possibile **sbilanciamento** del dataset o una definizione dell’accuracy non allineata all’obiettivo (es. molti negativi corretti ma zero positivi identificati).\n- *logo* è il best performer complessivo (F1 ≈ 0.999): indica che quando il segnale è presente è estremamente discriminante; attenzione però alla **copertura** (non visibile dal grafico).\n- *query-name_like* e *similarity* hanno precision più bassa (≈ 0.854 e ≈ 0.896) pur mantenendo recall = 1.0: probabili **falsi positivi** dovuti a ambiguità nei nomi o similarità testuale troppo permissiva.\n- *xgboost* è l’unico metodo “alto” con recall sensibilmente < 1.0: potrebbe essere utile come componente di *ensemble* o come *fallback* “intelligente”, ma va migliorata la sensibilità.\n- *azure_model* mostra prestazioni robuste (F1 ≈ 0.972) e recall = 1.0, ma con precision inferiore alle migliori *query*: potenziale margine di miglioramento su disambiguazione e soglie.\n\n---\n\n## Raccomandazioni operative\n\n- Definire un *routing* gerarchico basato su **precision attesa** e affidabilità del segnale:\n  - Prima scelta: *logo* (se rilevabile) e *query-supplier_code*.\n  - Seconda fascia: *query-vat_number*, *query-fiscal_code*, *query-phone*, *query-supplier_name*.\n  - Terza fascia (più rischiosa): *similarity* e *query-name_like* con soglie più conservative.\n- Introdurre soglie e regole di disambiguazione per i metodi ad alto recall ma precision più bassa (*similarity*, *query-name_like*):\n  - limitare a top-1 con margine minimo sul secondo candidato,\n  - richiedere coerenza multi-campo (es. nome + P.IVA/telefono) prima di confermare.\n- Rivedere la metrica di **accuracy** per *no_method* e *fallback*:\n  - verificare come vengono conteggiati i negativi,\n  - affiancare sempre metriche orientate ai positivi (F1, recall) e, se possibile, riportare anche la **coverage** per metodo (quota di documenti su cui il metodo è applicabile).\n- Potenziare *xgboost* per aumentare recall:\n  - calibrazione soglia decisionale, gestione class imbalance, feature addizionali (campi chiave estratti, segnali di confidenza OCR),\n  - valutare un *ensemble* in cui *xgboost* interviene quando le *query* non restituiscono match affidabili.\n- Validare le modifiche con *A/B test* o replay su set temporali separati, monitorando non solo F1 ma anche **tasso di falsi positivi** (impatto operativo su riconciliazione/validazione manuale).\n:::\n:::\n\n\n### Confronto ML vs Query-based\n\n::: {#cell-fig-ml-vs-query .cell fig-height='6' fig-width='10' execution_count=13}\n\n::: {.cell-output .cell-output-display}\n![Confronto performance tra metodi ML, Query-based e Other](report_lucy_files/figure-html/fig-ml-vs-query-output-1.png){#fig-ml-vs-query width=950 height=566 fig-pos='H'}\n:::\n:::\n\n\n::: {#5f66b415 .cell execution_count=14}\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Commento AI:** Dai dati emerge un quadro molto netto: i metodi *ML* e *Query* mostrano performance **quasi sovrapponibili e molto elevate**, con *recall* pari a **1.0** e *f1* ~**0.97**. Questo indica una capacità eccellente di intercettare i casi positivi (nessun *false negative* nel campione) e una qualità complessiva molto stabile tra le due famiglie di approcci.\n\nAl contrario, la categoria *Other* evidenzia un degrado marcato su *precision* (~**0.57**), *recall* (~**0.55**) e *f1* (~**0.56**), pur mantenendo un’*accuracy* alta (~**0.94**). Il pattern suggerisce un possibile effetto di sbilanciamento delle classi: l’*accuracy* resta elevata anche quando la capacità di riconoscere correttamente la classe “rilevante” è debole.\n\n---\n\n## Punti di interesse/anomalie\n\n- **Paradosso “alta accuracy, bassa f1” per *Other***  \n  - *accuracy* ~0.94 è vicina a *ML*/*Query*, ma *f1* crolla a ~0.56: tipico segnale che l’*accuracy* da sola non è una metrica affidabile nel contesto (probabile prevalenza della classe negativa o logiche conservative che evitano predizioni positive).\n- ** *Recall* = 1.0 per *ML* e *Query***  \n  - Risultato ottimo, ma “perfetto” può indicare anche dataset piccolo, poco vario, o valutazione su un sottoinsieme non rappresentativo. Da verificare con split robusti e casistiche edge.\n- **Differenza tra *precision* e *recall* in *ML*/*Query***  \n  - Con *recall* perfetto e *precision* ~0.946, gli errori residui sono principalmente *false positive* (estrazioni/riconoscimenti attivati quando non dovrebbero).\n- **Prestazioni quasi identiche tra *ML* e *Query***  \n  - Può indicare che i due metodi lavorano su segnali molto simili o che l’attuale pipeline/applicazione dei *query-based* copre già bene il dominio (utile per strategie di *routing* o *fallback*).\n\n---\n\n## Raccomandazioni operative\n\n- **Ricalibrare la valutazione mettendo *f1*, *precision* e *recall* al centro (non l’*accuracy*)**  \n  - Definire soglie e criteri di accettazione basati su *f1* e sull’impatto business dei *false positive* vs *false negative*.\n- **Segmentare l’analisi per tipologia di fattura e campo estratto**  \n  - Valutare separatamente layout, lingua, qualità OCR, fornitori ricorrenti e campi critici (es. IVA, totale, data) per capire dove *Other* fallisce e dove *ML*/*Query* generano *false positive*.\n- **Implementare *routing* tra *Query* e *ML* con logiche di confidenza**  \n  - Esempio: usare *Query* su pattern/ancore ad alta affidabilità; passare a *ML* su layout variabili; attivare un *fallback* (o revisione) quando la confidenza è bassa o le regole non matchano.\n- **Ridurre i *false positive* su *ML*/*Query***  \n  - Introdurre controlli di coerenza (validazioni formali, checksum, range plausibili) e post-processing; dove possibile, un piccolo *ensemble* (regola + modello) per confermare i casi borderline.\n- **Intervenire su *Other* o deprecarlo gradualmente**  \n  - Se *Other* rappresenta metodi legacy/euristici: pianificare un phase-out o un uso limitato come *fallback* solo in scenari specifici, dopo un’analisi errori mirata.\n- **Validazione più robusta con *A/B test* o holdout temporale**  \n  - Misurare la stabilità nel tempo e su nuovi fornitori/layout, evitando che performance “perfette” (es. *recall* 1.0) siano artefatti di campionamento.\n:::\n:::\n\n\n## Analisi Errori\n\n### Distribuzione Errori\n\n::: {#ba6b8ca6 .cell execution_count=15}\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Distribuzione Errori (Tutti i Campi)**\n\n| Metrica             | Valore   |\n|:--------------------|:---------|\n| True Positive (TP)  | 14,374   |\n| False Positive (FP) | 655      |\n| False Negative (FN) | 1,544    |\n| True Negative (TN)  | 2,713    |\n:::\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Errori per Metodo (Tutti i Campi)**\n\n| method_pred         |   FN |   FP |\n|:--------------------|-----:|-----:|\n| azure_model         |    0 |  253 |\n| logo                |    0 |    2 |\n| query-fiscal_code   |    0 |    1 |\n| query-name_like     |    0 |   43 |\n| query-phone         |    0 |   13 |\n| query-supplier_code |    0 |    1 |\n| query-supplier_name |    0 |   16 |\n| query-vat_number    |    0 |   35 |\n| similarity          |    0 |   83 |\n| xgboost             | 1520 |  208 |\n:::\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Errori per Campo (field_name)**\n\n| field_name    |   FN |   FP |\n|:--------------|-----:|-----:|\n| autovalidated | 1520 |  208 |\n| id_subject    |   24 |  447 |\n:::\n:::\n\n\n### Matrice di Confusione - Azure Model\n\n::: {#cell-fig-confusion-azure .cell fig-height='5' fig-width='6' execution_count=16}\n\n::: {.cell-output .cell-output-display}\n![Matrice di confusione per Azure Model (ML/XGBoost)](report_lucy_files/figure-html/fig-confusion-azure-output-1.png){#fig-confusion-azure width=545 height=469 fig-pos='H'}\n:::\n:::\n\n\n::: {#bb90e6d4 .cell execution_count=17}\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Commento AI:** La matrice di confusione dell’*Azure Model (ML/XGBoost)* mostra una forte concentrazione di risultati in **True Positive (TP=4457)**, con un numero contenuto di **False Positive (FP=253)**. Questo indica che, quando il modello segnala la presenza/estrazione corretta dell’informazione target (scenario “positivo”), nella maggior parte dei casi ha ragione.\n\nAl tempo stesso, l’assenza di **False Negative (FN=0)** suggerisce **recall pieno** sul set valutato: il modello non “perde” casi positivi. Tuttavia, la presenza di **TN=0** rende l’interpretazione **sbilanciata**: la valutazione sembra effettuata su un campione quasi esclusivamente positivo (o con definizione di classe negativa non rappresentata), limitando la capacità di stimare affidabilmente la specificità e il comportamento del modello sui “non-casi”.\n\n---\n\n## Punti di interesse/anomalie\n\n- **Distribuzione classi non bilanciata / classe negativa assente**\n  - Con **TN=0** non è possibile valutare metriche chiave legate alla classe negativa (es. specificità), e il rischio di sovrastimare la bontà complessiva aumenta.\n- **Presenza di FP non trascurabile (253)**\n  - Anche con recall elevato, gli *FP* possono generare **estrazioni/validazioni errate** a valle (es. campi riconosciuti dove non dovrebbero esserci), con impatto su controlli contabili o *routing* del processo.\n- **FN=0 potenzialmente indicativo di soglia molto permissiva**\n  - Un comportamento “mai negativo” può derivare da:\n    - soglia decisionale troppo bassa,\n    - definizione del “positivo” troppo ampia,\n    - dataset di test costruito solo su esempi positivi (o su pagine/righe già filtrate).\n- **Metriche derivate (utile come riferimento)**\n  - *Precision* ≈ 4457 / (4457+253) ≈ **94,6%**\n  - *Recall* = 4457 / (4457+0) = **100%**\n  - Queste metriche restano comunque **condizionate** dall’assenza di casi negativi misurabili (TN).\n\n---\n\n## Raccomandazioni operative\n\n- **Integrare un set di test con veri negativi**\n  - Inserire documenti/pagine/campi “non target” per misurare **specificità**, *false alarm rate* e robustezza su casi reali (fatture con layout atipici, documenti non-fattura, campi assenti).\n- **Ricalibrare la soglia decisionale per ridurre *FP***\n  - Valutare una taratura della confidence o un *thresholding* per ottimizzare il trade-off *precision/recall* in funzione del costo operativo degli errori.\n- **Analizzare gli *FP* per cluster di causa**\n  - Campionare e categorizzare gli *FP* (layout, lingua, qualità OCR, template, campi vicini semanticamente) per identificare interventi mirati (feature, pulizia input, regole).\n- **Aggiungere controlli di validazione a valle come *fallback***\n  - Introdurre regole di coerenza (formati, checksum, range, cross-field validation) e un *fallback* verso metodi alternativi quando la confidence è bassa o i vincoli falliscono.\n- **Misurare con *A/B test* su flusso end-to-end**\n  - Verificare l’impatto reale su KPI operativi (tempi di revisione, tasso di correzioni manuali, errori contabili) confrontando configurazioni diverse di *azure_model* e soglie.\n:::\n:::\n\n\n### Analisi Pattern di Errore\n\n\n\n## 1) Metodi con più problemi (FP / FN)\n\n- **False Positive (FP) dominanti**\n  - *azure_model*: **253 FP** → principale fonte di FP (probabile sovra-attivazione o regole troppo permissive).\n  - *xgboost*: **208 FP** → secondo contributore; indica che il classificatore tende a “vedere” segnali positivi anche quando non ci sono.\n  - *similarity*: **83 FP** → errori tipici da matching testuale (stringhe simili ma non corrette).\n  - Query-based con FP non trascurabili:\n    - *query-name_like* (43), *query-vat_number* (35), *query-supplier_name* (16), *query-phone* (13)\n  - Metodi marginali: *logo* (2), *query-supplier_code* (1), *query-fiscal_code* (1)\n\n- **False Negative (FN) dominanti**\n  - *xgboost*: **1520 FN** → **problema principale dell’intero sistema** lato copertura/recall.\n  - Assenza di FN sugli altri metodi (nei dati forniti) → indica che *xgboost* è probabilmente l’ultimo “decisore” o che il *routing* indirizza molti casi a *xgboost* e lì vengono persi.\n\n**Lettura complessiva**\n- Il sistema sembra soffrire di:\n  - **Alta “aggressività”** su *azure_model* (molti FP)\n  - **Bassa copertura** su *xgboost* (molti FN), pur avendo anche FP rilevanti → possibile problema di soglia, calibrazione o sbilanciamento feature/dati.\n\n---\n\n## 2) Confidence e correlazione con gli errori\n\n- Confidence media:\n  - FP: **0.662**\n  - FN: **0.698**\n- Anomalia importante: i FN hanno confidence **più alta** dei FP.\n  - Questo suggerisce che la confidence **non è ben calibrata** rispetto alla correttezza (cioè non riflette bene la probabilità reale di essere corretti).\n  - In pratica: il sistema può essere **molto “sicuro” anche quando sbaglia** (soprattutto nei FN), segnale tipico di:\n    - *calibration* assente o inefficace\n    - *dataset shift* (fatture nuove/fornitori nuovi/format diversi)\n    - soglia decisionale non ottimizzata per il trade-off FP/FN\n\n- Implicazione operativa:\n  - Usare solo la confidence come *fallback trigger* rischia di essere inefficace, perché gli errori non stanno “a bassa confidence”.\n\n---\n\n## 3) Miglioramenti e aree di attenzione\n\n### A) Azioni mirate per ridurre i **FN di *xgboost***\n- **Rivedere soglia e funzione obiettivo**\n  - Ottimizzare la soglia per massimizzare *recall* (ridurre FN) se il costo dei FN è alto.\n  - Valutare training con pesi classe o obiettivi orientati a *recall* / *F2*.\n- **Analisi per sottocasi (error slicing)**\n  - Segmentare i 1520 FN per:\n    - tipo campo estratto (VAT, nome fornitore, totale, IBAN, ecc.)\n    - layout/lingua/Paese\n    - presenza OCR rumoroso, scansioni, qualità immagine\n  - Spesso i FN si concentrano su pochi pattern ripetitivi.\n- **Aggiungere un *fallback* o *ensemble***\n  - Se *xgboost* fallisce, attivare una seconda via (es. regole *query-* o *azure_model*) con vincoli più stretti.\n  - Alternativamente un *ensemble* “conservativo” per dire positivo se almeno un metodo altamente affidabile concorda.\n\n### B) Azioni mirate per ridurre i **FP di *azure_model*** (e *xgboost*)\n- **Vincoli post-estrazione (validazioni)**\n  - Per campi strutturati (es. VAT/telefono): validazione formato, checksum, lunghezza, country prefix.\n  - Per nomi: blacklist/stopword, coerenza con contesto (es. vicino a “Supplier”, “Vendor”, intestazione).\n  - Queste validazioni tagliano FP senza impattare troppo i FN.\n- **Raffinare il *routing***\n  - Limitare quando *azure_model* può emettere un positivo (es. solo se in regioni del documento plausibili o con keyword di supporto).\n- **Ridurre ambiguità del matching**\n  - Su *similarity* e *query-name_like*: introdurre soglie dinamiche per lunghezza stringa e penalità per match parziali.\n\n### C) Confidence: rendere la stima “affidabile” per decisioni automatiche\n- **Calibrazione della confidence** (*calibration*)\n  - Applicare metodi come Platt scaling / isotonic (a seconda del modello) per riallineare confidence e accuratezza reale.\n- **Soglie diverse per metodo (per-metodo, non globali)**\n  - Visto che FP e FN si concentrano su metodi diversi, una soglia unica è probabilmente subottimale.\n- **Score composito**\n  - Integrare confidence con segnali di qualità: qualità OCR, presenza di keyword, validazioni superate, posizione sul layout.\n\n---\n\n## Sintesi operativa (priorità)\n- **Priorità 1:** ridurre i **1520 FN di *xgboost*** (è il collo di bottiglia di recall).\n- **Priorità 2:** contenere i **253 FP di *azure_model*** con validazioni e *routing* più restrittivo.\n- **Priorità 3:** intervenire sulla **calibrazione della confidence**: oggi non separa bene errori e successi (FN addirittura più “sicuri” dei FP).\n\n\n## Distribuzione Confidence\n\n::: {#cell-fig-confidence .cell fig-height='6' fig-width='12' execution_count=20}\n\n::: {.cell-output .cell-output-display}\n![Distribuzione della confidence per metodo](report_lucy_files/figure-html/fig-confidence-output-1.png){#fig-confidence width=1142 height=565 fig-pos='H'}\n:::\n:::\n\n\n::: {#c972941c .cell execution_count=21}\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Commento AI:** La distribuzione complessiva della *confidence* mostra un livello medio **buono** (media = **0.815**), indicativo di prestazioni generalmente solide degli algoritmi di riconoscimento documentale sulle fatture. Tuttavia, la dispersione è significativa (Std = **0.219**), suggerendo che la qualità dell’estrazione non è uniforme e che coesistono casi molto affidabili e casi più incerti.\n\nIn un *box plot* “per metodo”, questo profilo è tipicamente compatibile con metodi che, pur avendo una mediana elevata, presentano **code lunghe** o un numero non trascurabile di valori bassi: segnali di sensibilità a variabilità di layout, qualità scansione, lingua, o tipologie di fattura. La lettura chiave è quindi il compromesso tra **accuratezza media** e **stabilità** (IQR e outlier) tra i diversi metodi.\n\n---\n\n## Punti di interesse/anomalie\n\n- **Variabilità elevata**: una Std di **0.219** implica che la *confidence* può oscillare sensibilmente tra documenti e/o tra metodi, con impatto diretto su *SLA* e necessità di revisione manuale.  \n- **Possibile presenza di outlier a bassa confidence**: in un contesto fatture, valori molto bassi spesso indicano:\n  - documenti con layout non standard (note di credito, pro-forma, fatture estere)\n  - scansioni degradate (rumore, skew, bassa risoluzione)\n  - campi critici (es. VAT, IBAN, totali) con ambiguità o formattazioni non canoniche\n- **Rischio di “falsa sicurezza” su medie aggregate**: una media a 0.815 può mascherare metodi con mediana simile ma **IQR molto diverso** (metodi “stabili” vs metodi “volatili”).  \n- **Eterogeneità per metodo** (da verificare visivamente nel box plot): differenze marcate tra mediane e ampiezza della box possono suggerire opportunità di *routing* o *ensemble* per ridurre la varianza.\n\n---\n\n## Raccomandazioni operative\n\n- Introdurre soglie operative basate su *confidence* con gestione a livelli:\n  - **auto-approvazione** sopra una soglia alta (es. ≥ 0.90)\n  - **validazione assistita** in fascia intermedia (es. 0.70–0.90)\n  - *fallback* o revisione manuale sotto soglia (es. < 0.70)\n- Abilitare *routing* “per metodo” o “per tipologia documento”:\n  - scegliere il metodo con **mediana più alta** e **IQR più stretto** per i casi standard\n  - deviare casi complessi verso metodi più robusti o pipeline specializzate (es. layout complessi)\n- Valutare un approccio *ensemble* (quando applicabile) per:\n  - ridurre l’impatto degli outlier\n  - aumentare la stabilità su campi critici (totali, date, VAT)\n- Pianificare un *A/B test* focalizzato su stabilità e qualità:\n  - confrontare non solo la media, ma anche **IQR**, percentili (P10/P50/P90) e tasso di casi sotto soglia\n- Analisi mirata degli errori sui documenti a bassa *confidence*:\n  - clustering per fonte/fornitore, lingua, qualità immagine, template\n  - arricchimento della fase di pre-processing (deskew, denoise, binarizzazione) dove emerge correlazione con i valori bassi\n\nSe vuoi, posso adattare il commento includendo riferimenti espliciti a ciascun metodo (es. *azure_model*, *query-vat_number*, ecc.) non appena condividi i nomi dei metodi presenti nel box plot e un’indicazione visiva di mediane/outlier per ciascuno.\n:::\n:::\n\n\n## Analisi Geografica\n\n### Accuracy per Country e Metodo\n\n::: {#cell-fig-accuracy-heatmap .cell fig-height='10' fig-width='14' execution_count=22}\n\n::: {.cell-output .cell-output-display}\n![Heatmap dell'accuratezza per country e metodo](report_lucy_files/figure-html/fig-accuracy-heatmap-output-1.png){#fig-accuracy-heatmap width=1201 height=950 fig-pos='H'}\n:::\n:::\n\n\n::: {#219e078f .cell execution_count=23}\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Commento AI:** La heatmap (57 *countries* × 12 *metodi*) evidenzia un pattern di **eterogeneità geografica**: l’accuratezza non è uniforme tra i Paesi e tende a concentrarsi in “fasce” (cluster) dove alcuni *countries* risultano sistematicamente più facili (valori mediamente più alti su più metodi) e altri più complessi (valori più bassi o molto variabili). Questo suggerisce che la performance è influenzata da fattori strutturali (layout locali delle fatture, lingua, formati fiscali, qualità scansioni) oltre che dal metodo in sé.\n\nDal lato metodi, si osserva tipicamente una **stabilità differenziata**: alcuni metodi mantengono un comportamento più consistente cross-country (varianza più bassa), mentre altri appaiono più “sensibili” al contesto locale con oscillazioni marcate (celle molto più chiare/scure in funzione del Paese). In un’ottica di produzione, questa combinazione indica che un approccio di *routing* e/o *ensemble* può essere più efficace di un singolo metodo “one-size-fits-all”.\n\n---\n\n## Punti di interesse/anomalie\n\n- **Paesi con dispersione alta tra metodi**: presenza di righe “a zebra” (celle molto variabili).  \n  - Implicazione: il problema non è solo la difficoltà del Paese, ma la **mancata adattività** del metodo; potenziale beneficio da *routing* per country o per famiglia di layout.\n\n- **Metodi con performance polarizzata**: colonne con prestazioni molto alte in alcuni Paesi e molto basse in altri.  \n  - Implicazione: questi metodi potrebbero essere ottimi “specialisti” da attivare via *fallback* selettivo o come componente di un *ensemble*.\n\n- **Cluster geografici**: gruppi di Paesi con pattern simili (righe con distribuzioni comparabili).  \n  - Implicazione: opportunità di definire “region model packs” o configurazioni per macro-aree (es. stesso set di regole, dizionari o validatori VAT).\n\n- **Celle isolate anomale** (outlier): singole combinazioni country-metodo con cali improvvisi rispetto ai vicini.  \n  - Possibili cause: campioni piccoli, mix documentale atipico, problemi di encoding/lingua, regressioni di pipeline o configurazione OCR.\n\n- **Soffitto prestazionale**: se alcune aree della heatmap risultano uniformemente alte, può indicare *ceiling effect*.  \n  - Implicazione: per quei Paesi, investire in ottimizzazione fine potrebbe rendere meno rispetto a intervenire sui Paesi “difficili”.\n\n---\n\n## Raccomandazioni operative\n\n- Implementare un *routing* per country (o cluster di country) che selezioni il miglior metodo atteso, con regole semplici iniziali e affinamento progressivo:\n  - prima versione: best-per-country sulla base della media storica\n  - versione evoluta: routing per tipologia documento/layout e qualità immagine\n\n- Introdurre un meccanismo di *fallback* controllato:\n  - se il metodo primario non supera soglie di confidenza (o fallisce validazioni), attivare un secondo metodo “robusto”\n  - loggare in modo esplicito le attivazioni di *fallback* per analisi delle cause\n\n- Valutare un *ensemble* mirato per campi critici (es. supplier, VAT, totals), combinando:\n  - metodi “generalisti” (stabili cross-country)\n  - metodi “specialisti” (eccellenti su subset di Paesi)\n\n- Pianificare un *A/B test* per validare miglioramenti su segmenti ad alto volume:\n  - priorità ai Paesi con **alta varianza** e/o basso livello medio\n  - metriche: accuracy per campo, tasso di eccezioni, tempi di elaborazione, costo per documento\n\n- Rafforzare la diagnostica per outlier:\n  - controllo di numerosità campione per country-metodo\n  - report di regressione per release e configurazioni\n  - audit su qualità input (DPI, skew, compressione) e presenza di template locali\n\nSe condividi il grafico (immagine) o i valori sintetici (top/bottom country e metodi), posso rendere il commento più specifico citando pattern concreti (es. quali Paesi sono cluster “difficili” e quali metodi mostrano maggiore stabilità).\n:::\n:::\n\n\n## Conclusioni e Raccomandazioni\n\n### Metriche Chiave\n\n::: {#3332c477 .cell execution_count=24}\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Riepilogo Performance**\n\n| Metrica              | Valore                      |\n|:---------------------|:----------------------------|\n| Accuracy media       | 0.942                       |\n| Precision media      | 0.790                       |\n| Recall media         | 0.814                       |\n| F1 media             | 0.800                       |\n| Metodo migliore (F1) | logo (F1=0.999)             |\n| Metodo più usato     | xgboost (36,336 predizioni) |\n:::\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n**Confronto ML vs Query**\n\n| Tipo   |   Accuracy media |   F1 media |\n|:-------|-----------------:|-----------:|\n| ML     |            0.946 |      0.972 |\n| Query  |            0.946 |      0.972 |\n:::\n:::\n\n\n### Raccomandazioni\n\n\n\n### Raccomandazioni\n\nDalle metriche emerge che le componenti basate su query e i segnali “forti” (logo) offrono prestazioni molto elevate e stabili: per quasi tutte le query si osserva recall pari a 1,00 e F1 compreso tra 0,92 e 0,99, con precision generalmente alta (es. query-supplier_code F1=0,994; query-vat_number F1=0,987; logo F1=0,999). Anche il modello azure_model risulta solido (precision 0,946; recall 1,00; F1 0,972), confermando che le logiche deterministiche e i modelli ML pre-addestrati stanno catturando correttamente la maggior parte dei casi. Al contrario, xgboost mostra un recall sensibilmente inferiore (0,774) pur mantenendo una precision elevata (0,962), segnale di un comportamento più conservativo che genera molte mancate identificazioni. La distribuzione complessiva degli errori (FN=1544 contro FP=655) conferma che il problema principale è la copertura: il sistema perde più casi di quanti ne sbagli per eccesso.\n\nLe raccomandazioni prioritare sono quindi orientate a ridurre i falsi negativi, intervenendo soprattutto sul ramo xgboost e sull’orchestrazione delle regole. In primo luogo, va rivista la soglia decisionale e la calibrazione delle probabilità di xgboost, ottimizzando esplicitamente per recall o per un F-beta che pesi maggiormente il recall, dato che l’impatto maggiore è sui FN. In parallelo è utile arricchire le feature con segnali già dimostrati efficaci (esiti delle query, similarity, presenza/qualità del logo, confidenze OCR, pattern su campi chiave) e riequilibrare il training (gestione class imbalance, hard negatives e campioni borderline) per ridurre la tendenza del modello a non assegnare una classe. Infine, conviene introdurre una logica di gating/ensemble che privilegi le query quando presenti segnali deterministici affidabili (vat number, fiscal code, supplier code) e utilizzi xgboost come supporto nei casi ambigui, invece che come decisore principale.\n\nIn termini di qualità operativa, è raccomandato anche un lavoro mirato sulla riduzione dei falsi positivi (655), senza penalizzare eccessivamente il recall: ad esempio migliorando la normalizzazione dei testi (spazi, punteggiatura, OCR noise), rafforzando i controlli di coerenza tra campi (es. coerenza tra ragione sociale e P.IVA/codice fiscale) e introducendo soglie dinamiche basate sulla qualità dell’input (bassa confidenza OCR o documenti rumorosi richiedono evidenze multiple prima di confermare). Infine, le voci no_method e fallback con accuracy 1,00 ma precision/recall nulli indicano categorie “non operative” o non valutate in modo utile: è opportuno chiarirne il ruolo (es. gestione “non classificabile”) e misurarle con metriche coerenti (coverage e tasso di escalation), così da rendere il reporting più aderente al comportamento reale del sistema e guidare meglio le priorità di miglioramento.\n\n\n",
    "supporting": [
      "report_lucy_files\\figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}